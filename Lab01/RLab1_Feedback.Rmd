---
title: "R Coding Lab Part 1"
output: rmdformats::html_docco
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
colorize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color,
      x)
  } else x
}
```


```{r}
library(dplyr)
```

**Complete the following lab as a group. One of your team members should clone this repo to your GitHub, add your teammates and work on the lab as a Git repo from RStudio. Complete every problem in the Lab, including those of the project that you are not working on. Your code should be heavily commented so someone reading your code can follow along easily. See the first code snippet below for an example of commented code.**


**Here's the catch: For any given problem, the person writing the code should not be the person commenting that code, and every person must both code AND comment at least one problem in this lab (you decide how to split the work). This will involve lots of pushing and pulling through Git, and you may have to resolve conflicts if you're not careful! Refer to last Thursday's class notes for details on conflict resolution.**

**Use only tools covered on Tuesday's lecture (including those discussed on the lecture recording)**.


# Playing With Cherry Blossom Race Data

1) First load the data, which is saved as a .RData file called `CBdata_1_10.RData`. This is the first ten years' worth of Cherry Blossom Race data. Pull out the data associated with 1976 and store it as a data frame called `dat.76`. Remove the column `Pis/Tis`. 

`r colorize("Good 2/2: +1 Code, +1 Comment","red")`

```{r import_data}
load("CBdata_1_10.RData") #Loading the cherry blossom data. (this is an example of a properly commented line of code)


dat.76 <- data.frame(CBdata.1_10[4]) #Extracting the data for 1976 and storing it in a data frame called dat.76
dat.76 <- dat.76[-6] #Removing the column Pis/Tis
```


2) The function `summary()` is useful for learning basic facts about vectors, data frames, and many other R objects. Use this function to find the mean and median recorded ages in 1976. 

`r colorize("Good 2/2: +1 Code, +1 Comment","red")`

```{r summary}
summary(dat.76$Age) #Using the summary function to find the mean and median recorded ages in 1976
```

3) You might have noticed that a number of age values are missing (i.e. `NA`). Your next goal is to write a loop that removes observations that don't have age data.  
Hints:  
- The `is.na()` function may be useful. Use the `?is.na` command to pull up documentation on this function. It might be helpful to play around with a toy example like `c(1,2,NA,3)` to make sure you understand this new function!  
- Depending on how you write your code, you may need to negate a logical vector using `!`. Ex: `!c(TRUE, TRUE, FALSE)` is identical to `c(FALSE, FALSE, TRUE)`.

`r colorize("Good 3/3: +2 Code, +1 Comment","red")`

```{r filter_missing_age_loop}
dat.76.clean = as.data.frame(matrix(ncol=9,nrow=0)) #Creating an empty data frame to store the cleaned data
for(i in 1:length(dat.76$Age)){                     #Looping through the data frame to remove observations that don't have age                                                        data
  if(!is.na(dat.76$Age[i])){
    dat.76.clean = rbind(dat.76.clean, dat.76[i,])
  }else{dat.76.clean = dat.76.clean}
}
```



 4) Now use vectorization and the `is.na()` function to accomplish the same thing as the loop above.  
How to check your work: If your loop produced a data frame called "dat.76.clean" and the vectorization approach produced a data frame called `dat.76.clean2`, the `identical(dat.76.clean,dat.76.clean2)` should return `TRUE`.

`r colorize("Good 2/2: +1 Code, +1 Comment, but there is no need to use as.data.frame to create an empty df here. You simply assign the subsetted version to the new name dat.76.clean2 and that's it.","red")`

```{r filter_missing_age_vectorization}
dat.76.clean2 = as.data.frame(matrix(ncol=9,nrow=0)) #Creating a second empty data frame to store the cleaned data
dat.76.clean2 <- dat.76[!is.na(dat.76$Age),] #Using vectorization to remove observations that don't have age data
identical(dat.76.clean, dat.76.clean2) #Checking if the two approaches produced the same data frame
```




5) Filtering out missing age data could be useful when dealing with other years. With this in mind, turn your filter loop or vectorization approach into a function. You should be able to use the function like this: `dat.76.clean <- filter.func(dat.76)`.  
When you have a function written, run it on the 1976 data and use identical() to verify that your function and the first loop you wrote are doing the same thing.

`r colorize("Good 2/2: +1 Code, +1 Comment","red")`

```{r filter_func}
filter.func <- function(df){  #Now we are creating a function to remove observations that don't have age data
  df <- df[!is.na(df[[3]]),]
}
dat.76.clean3 <- filter.func(dat.76)
identical(dat.76.clean, dat.76.clean3) #Checking if the function and the first loop are doing the same thing
```




6) Next, write a loop that combines all of the data from `CBdata.1_10` into one cleaned data frame. Make sure your final data frame has neither the `Pis/Tis` column nor `NA` Age values.  
Use the `identical()` function to verify that the 1976 data in this larger cleaned data set is the same as the cleaned version of `dat.76`. 

`r colorize("Good 4/4: +3 Code, +1 Comment","red")`

```{r combine_dat}
CBdata.clean = as.data.frame(matrix(ncol=9,nrow=0)) #we create a final empty data frame to store the cleaned data
for(i in 1:length(CBdata.1_10)){ #we loop through the data frame to remove observations that don't have age data
  df = data.frame(CBdata.1_10[i]) #we create a temporary data frame to store the data for each year
  df = df[-6] #we remove the column Pis/Tis
  CBdata.clean = rbind(CBdata.clean, df[!is.na(df[[3]]),]) 
}
CBdata.clean.76  = subset(CBdata.clean, Year == "1976")
identical(row.names(dat.76.clean)<-NULL, row.names(CBdata.clean.76)<-NULL) #we check if the 1976 data in the larger cleaned data set is the same as the cleaned version of dat.76
```




7) Now that you have the combined data set for these 10 years, let's do some basic exploration:  
a) How does the average of the recorded ages in 1976 compare to that same average over the entire `CBdata_1_10` data set? 

`r colorize("Good 1/1: +1 Code, some interpretation would be useful though. Why could the mean over the entire data set be higher?","red")`

```{r}
mean(dat.76.clean$Age)
mean(CBdata.clean$Age)

```




b) Recall that the `CBdata_1_10` contains the first ten year's worth of cherry blossom race data. How does the average participant age over the first five years compare to the average age over years 6-10?

`r colorize("Good 1/1: +1 Code, same as before, some interpretation would be useful.","red")`

```{r}
mean(subset(CBdata.clean, Year %in% c("1973", "1974", "1975", "1976", "1977"))$Age)
mean(subset(CBdata.clean, Year %in% c("1978", "1979", "1980", "1981", "1982"))$Age)
```



# Playing with the indoor positioning system data

The `IPS_sampledata` data set contains a fraction of the indoor positioning system data for 15 randomly sampled locations.This data set is loaded into memory using the chunk of R code below, complete the following exercises. 

```{r eval=T, echo=T}
# loads data set IPS_sampledata
load("IPS_portion.RData")
```

### Variable dictionary

- `time`: timestamp in milliseconds since midnight 01/01/1970 UTC

- `scanMac`: MAC address of the scanning device (this is a handheld device)

- `posX`, `posY` and `posZ`: the (x, y, z) physical coordinate of the scanning device

- `orientation`: degree orientation of the user carrying the scanning device in degrees

- `mac`: MAC address of an access point

- `signal`: signal strength in dBm (Decibel-milliwatts)

- `channel`: the channel frequency

- `type`: type of device (access point = 3, device in adhoc mode = 1)

### Let's clean up the data a bit

1. First apply the `summary` function to the `IPS_data` to get a sense of what is available in that data frame.

`r colorize("Good 2/2: +1 Code, +1 comments.","red")`

```{r}
#get an overview of each variable in the data frame
summary(IPS_sampledata)
summary(IPS_sampledata)
#examine its structure and contents
head(IPS_sampledata)
```



2. Identify variables that need any `class` conversion. Attempting to avoid code-replication as much as possible, convert these variables into the correct class type.

`r colorize(" 1.5/3: +0.5 out of 2 for Code, there is a lot of code-replication here, which was explicitly asked to be avoided","red")`

```{r}
# converting position variables to numeric to ensure they are treated as continuous values
IPS_sampledata$posX <- as.numeric(IPS_sampledata$posX)
IPS_sampledata$posY <- as.numeric(IPS_sampledata$posY)
IPS_sampledata$posZ <- as.numeric(IPS_sampledata$posZ)

# converting signal strength variables to numeric for accurate numerical analysis
IPS_sampledata$signal <- as.numeric(IPS_sampledata$signal)
IPS_sampledata$orientation <- as.numeric(IPS_sampledata$orientation)

# converting categorical variables to factors to optimize storage and facilitate categorical analysis
IPS_sampledata$scanMac <- as.factor(IPS_sampledata$scanMac)
IPS_sampledata$mac <- as.factor(IPS_sampledata$mac)
IPS_sampledata$channel <- as.factor(IPS_sampledata$channel)
IPS_sampledata$type <- as.factor(IPS_sampledata$type)

```



3. Because we only want data relative to access points, remove observations that correspond to any other type of device.

`r colorize(" 1.5/2: +0.5 out of 1 for Code (idea was to use subsetting as learned in class up to this point),  +1 comments","red")`

```{r}
# filter the data to keep only rows where the `type` variable is 3 (indicating access points)

IPS_sampledata <- IPS_sampledata %>% filter(type == 3)
```



4. Assess if there are any variables that provide redundant or no information. If so, remove them from the data frame.

`r colorize(" 1.5/2: +0.5 out of 1 for Code (you were to use subsetting as learned in class up to this point),  +1 comments","red")`

```{r}
#remove columns with only one unique value, since they provide redundant information
IPS_sampledata <- IPS_sampledata %>% select(where(~ n_distinct(.) > 1))
```



5. Note that the `time` variable is in milliseconds.  Transform it into seconds and then convert its class into a time format using the function `as.POSIXct`.

`r colorize(" 2/2: +1 for Code, +1 comments","red")`

```{r}
#checking if 'time' variable is numeric; if not convert to numeric 
if (!is.numeric(IPS_sampledata$time)) {
  IPS_sampledata$time <- as.numeric(IPS_sampledata$time)
}

IPS_sampledata$time <- IPS_sampledata$time / 1000 #convert time from milliseconds to seconds
IPS_sampledata$time <- as.POSIXct(IPS_sampledata$time, origin="1970-01-01", tz="UTC")

```




### Examining the data more closely

`r colorize("All R chunks below have the names incorrectly assigned, I fixed them so that the file would knit.","red")`

1. Create the function `tally_mac` whose only input is the MAC address of an access point, and returns the number of observations found in the data set for it.



`r colorize(" 2/2: +1 out of 1 for Code, +1 comments","red")`

```{r tally_mac, eval=T, echo=T}
# ```{r eval=T, echo=T tally_mac}

#function for tallying number of observations in the dataset for a MAC address
tally_mac <- function(mac_address){
  count <- sum(data$mac == mac_address, na.rm = TRUE)
  return(count)
}
```



2. Use the function `unique` to identify the unique levels for `mac` found in the data set. 

`r colorize(" 2/2: +1 out of 1 for Code, +1 comments","red")`

```{r unique_mac, eval=T, echo=T}
#```{r eval=T, echo=T unique mac}
unique_mac_addresses <- unique(IPS_sampledata$mac) #finding the unique MAC addresses
unique_mac_addresses
```



3. Using an approach learned in class together with `tally_mac`, tally the  number of observations for all access points in the data. While the researchers did their best to clean their data, some noise was introduced by access points on other floors.  Based on the number of counts, identify and remove likely suspects for access points read by mistake.

`r colorize(" 0.8/3: +0 out of 2 for Code (we did not go over this until last week and the funtion tally_mac was not used), +0.8 comments: no clear explanation of what each line does","red")` 

```{r filter_access_points, eval=T, echo=T}
#```{r eval=T, echo=T filter_access points}
library(dplyr)
#dataframe with mac addresses and their counts
mac_counts_df <- IPS_sampledata %>%
  group_by(mac) %>%
  summarize(count = n())

#filtering out the access points read by mistake
threshold <- 5
cleaned_mac_counts_df <- mac_counts_df %>%
  filter(count >= threshold)

```



4.  The orientation of the hand-held device considered was supposed to be exactly set to the 8 angles from 0-315 in increments of 45 degrees (360 is equivalent to 0). However, in practice the measured orientations were close to the 8 expected but had some error, so we'll need to group them.  Develop and apply a function to recode the orientation values as one of 0, 45, 90, 135, 180, 225, 270, 315. Call the recoded orientation variable `rec_orient`.

`r colorize("Good 3.8/4: +3 for Code,  +0.8 comments: it is not clear what kind of object orientation is, this should be explained since if it is a vector the fn will not work properly.","red")`

```{r rec_orient_variable, eval=T, echo=T}
#```{r eval=T, echo=T rec orient variable}
#setting orientation data to be numeric
IPS_sampledata$orientation <- as.numeric(IPS_sampledata$orientation)

#function to recode the orientation variable
recode_orientation <- function(orientation) {
   if (is.na(orientation)) {
    return(NA)
   }
  target_angles <- c(0, 45, 90, 135, 180, 225, 270, 315) #correct values
  #selecting the correct angle by how close the observed value is to the target value
  closest_angle <- target_angles[which.min(abs(target_angles - orientation))]
  
  return(closest_angle)
}
#creating new variable of recoded orientations
IPS_sampledata$rec_orient <- sapply(IPS_sampledata$orientation, recode_orientation)

head(IPS_sampledata) #check to see if it worked
```



5. Create the function `signal_summary` that takes as inputs a location (`posX`, `posY`, `posZ`), an orientation (`rec_orient`) and an access point id (`mac`).  The function must identify and subset the rows in `IPS_sampledata` corresponding to this unique combination, then it must calculate and return the mean and standard deviation for the corresponding signal strengths. 

`r colorize("1.8/4: +1 out of 3 for Code, notice that the variable is called signal and not signal_strength, also posZ was romoved in Q4. So your code does not work (I modified it to get it running),  +0.8 comments: it is good practice to define funtion inputs including a description of their types.","red")`

```{r singal_summary, eval=T, echo=T}
#```{r eval=T, echo=T singal_summary}
#function for the mean and sd of the signal strength for a location, orientation, and access point

#--- DTR: I modified you code to get it to run!
signal_summary <- function(posX, posY, posZ=NULL, rec_orient, mac) {
  #filtering data to the location, orientation, and access point specified 
  subset_data <- IPS_sampledata[
    IPS_sampledata$posX == posX &
    IPS_sampledata$posY == posY &
#---- DTR: Note that posZ was removed in Q4 because all values are 0
    #IPS_sampledata$posZ == posZ & 
    IPS_sampledata$rec_orient == rec_orient &
    IPS_sampledata$mac == mac, ]
  #calculating mean signal strength
  mean_signal <- mean(subset_data$signal, na.rm = TRUE)
  #mean_signal <- mean(subset_data$signal_strength, na.rm = TRUE)
  #calculating signal strength sd
  sd_signal <- sd(subset_data$signal, na.rm = TRUE)
  # sd_signal <- sd(subset_data$signal_strength, na.rm = TRUE)
  return(list(mean = mean_signal, sd = sd_signal))
}
```



6.  Create a list where each entry corresponds to a named list including unique combination of a location, an orientation, and an access point.  Use this list in combination with `lapply` and `signal_summary` to generate a summary of signals for each unique combination. `Hint`: you may want to create a new variable with a unique identifier that combines location, `rec_orient` and `mac` to make your life simpler.  One way to go about this is using the `paste` function (see `?paste` for help on its use) with these variables in a row-by-row fashion.

`r colorize("1.5/4: +0.5 out of (3) for Code, 1) because you used an apply function, your df was converted to an atomic (char) matrix, so all operations fail, 2) you included the posZ variable which was removed as part of Q4  (I modified your code to get it running),  +1 comments.","red")`

```{r Signal_Summaries_List, eval=T, echo=T}
#```{r eval=T, echo=T Signal Summaries List}

#---- DTR: since you chose to do it differently, the code below is not needed
#creating ID variable for each combination of location, orientation, and access point
#IPS_sampledata$unique_id <- with(IPS_sampledata, paste(posX, posY, posZ, rec_orient, mac, sep = "_"))
#data frame for only the unique combinations

#---- DTR: posZ was removed in Q4 from IPS_sampledata 
#unique_combinations <- unique(IPS_sampledata[c("posX", "posY", "posZ", "rec_orient", "mac")])
unique_combinations <- unique(IPS_sampledata[c("posX", "posY", "rec_orient", "mac")])
#list of each unique combination

##---- DTR: I modified your code slightly to get it running.

signal_summaries <- lapply(1:nrow(unique_combinations), function(rr) {
  combination <- unique_combinations[rr,]
  signal_summary(
    posX = combination$posX,
    posY = combination$posY,
    posZ = NULL,
    rec_orient = combination$rec_orient,
    mac = combination$mac
  )
})

#----- DTR: I commented your code out
# combination_list <- apply(unique_combinations, 1, function(row) {
#   list(posX = row["posX"], posY = row["posY"], posZ = row["posZ"], rec_orient = row["rec_orient"], mac = row["mac"])
# })
# #signal summary for each unique combination
# signal_summaries <- lapply(combination_list, function(combination) {
#   signal_summary(
#     posX = combination$posX,
#     posY = combination$posY,
#     posZ = combination$posZ,
#     rec_orient = combination$rec_orient,
#     mac = combination$mac
#   )
# })

```




boise state montana
portland montana
portland portland state
portland state montana
portland state washington
portland washington
